{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memory zone\n",
    "\n",
    "![zone01](resources/zone01.png)[ref](https://stackoverflow.com/questions/18061218/how-linux-kernel-decide-to-which-memory-zone-to-use)\n",
    "\n",
    "![zone02](resources/zone02.png)\n",
    "![zone03](resources/zone03.png)\n",
    "\n",
    "[x64 mem layout](https://unix.stackexchange.com/questions/509607/how-a-64-bit-process-virtual-address-space-is-divided-in-linux)\n",
    "\n",
    "[canonical address](https://en.wikipedia.org/wiki/X86-64#Virtual_address_space_details)\n",
    "\n",
    "---------------------\n",
    "\n",
    "## linux2.6/include/linux/mmzone.h\n",
    "\n",
    "```c\n",
    "#define ZONE_DMA\t\t0\n",
    "#define ZONE_NORMAL\t\t1\n",
    "#define ZONE_HIGHMEM\t\t2\n",
    "#define MAX_NR_ZONES\t\t3\n",
    "#define GFP_ZONEMASK\t0x03\n",
    "\n",
    "/*\n",
    " * One allocation request operates on a zonelist. A zonelist\n",
    " * is a list of zones, the first one is the 'goal' of the\n",
    " * allocation, the other zones are fallback zones, in decreasing\n",
    " * priority.\n",
    " *\n",
    " * Right now a zonelist takes up less than a cacheline. We never\n",
    " * modify it apart from boot-up, and only a few indices are used,\n",
    " * so despite the zonelist table being relatively big, the cache\n",
    " * footprint of this construct is very small.\n",
    " */\n",
    "struct zonelist {\n",
    "\tstruct zone *zones[MAX_NUMNODES * MAX_NR_ZONES + 1]; // NULL delimited\n",
    "};\n",
    "\n",
    "```\n",
    "1. define some consts\n",
    "\n",
    "```c\n",
    "/*\n",
    " * The pg_data_t structure is used in machines with CONFIG_DISCONTIGMEM\n",
    " * (mostly NUMA machines?) to denote a higher-level memory zone than the\n",
    " * zone denotes.\n",
    " *\n",
    " * On NUMA machines, each NUMA node would have a pg_data_t to describe\n",
    " * it's memory layout.\n",
    " *\n",
    " * Memory statistics and page replacement data structures are maintained on a\n",
    " * per-zone basis.\n",
    " */\n",
    "struct bootmem_data;\n",
    "typedef struct pglist_data {\n",
    "\tstruct zone node_zones[MAX_NR_ZONES];\n",
    "\tstruct zonelist node_zonelists[MAX_NR_ZONES];\n",
    "\tint nr_zones;\n",
    "\tstruct page *node_mem_map;\n",
    "\tunsigned long *valid_addr_bitmap;\n",
    "\tstruct bootmem_data *bdata;\n",
    "\tunsigned long node_start_pfn;\n",
    "\tunsigned long node_present_pages; /* total number of physical pages */\n",
    "\tunsigned long node_spanned_pages; /* total size of physical page\n",
    "\t\t\t\t\t     range, including holes */\n",
    "\tint node_id;\n",
    "\tstruct pglist_data *pgdat_next;\n",
    "\twait_queue_head_t       kswapd_wait;\n",
    "} pg_data_t;\n",
    "\n",
    "#define node_present_pages(nid)\t(NODE_DATA(nid)->node_present_pages)\n",
    "#define node_spanned_pages(nid)\t(NODE_DATA(nid)->node_spanned_pages)\n",
    "\n",
    "```\n",
    "\n",
    "1. NUMA node\n",
    "\n",
    "2. `node_mem_map` array of page descriptors of the node\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linux2.6/include/linux/gfp.h\n",
    "\n",
    "![gfp01](resources/gfp01.png)\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## buddy system algorithm\n",
    "\n",
    "![buddy01](resources/buddy01.png)\n",
    "![buddy02](resources/buddy02.png)\n",
    "\n",
    "-----------------\n",
    "\n",
    "## linux2.6/include/linux/mmzone.h\n",
    "\n",
    "```c\n",
    "struct free_area {\n",
    "\tstruct list_head\tfree_list;\n",
    "\tunsigned long\t\t*map;\n",
    "};\n",
    "\n",
    "/*\n",
    "    * free areas of different sizes\n",
    "    */\n",
    "struct free_area\tfree_area[MAX_ORDER];\n",
    "```\n",
    "1. free_area is the buddy list array of different orders.\n",
    "\n",
    "\n",
    "## linux2.6/mm/page_alloc.c\n",
    "\n",
    "### allocate one page\n",
    "\n",
    "```c\n",
    "/* \n",
    " * Do the hard work of removing an element from the buddy allocator.\n",
    " * Call me with the zone->lock already held.\n",
    " */\n",
    "static struct page *__rmqueue(struct zone *zone, unsigned int order)\n",
    "{\n",
    "\tstruct free_area * area;\n",
    "\tunsigned int current_order;\n",
    "\tstruct page *page;\n",
    "\tunsigned int index;\n",
    "\n",
    "\tfor (current_order = order; current_order < MAX_ORDER; ++current_order) {\n",
    "\t\tarea = zone->free_area + current_order;\n",
    "\t\tif (list_empty(&area->free_list))\n",
    "\t\t\tcontinue;\n",
    "\n",
    "\t\tpage = list_entry(area->free_list.next, struct page, list);\n",
    "\t\tlist_del(&page->list);\n",
    "\t\tindex = page - zone->zone_mem_map;\n",
    "\t\tif (current_order != MAX_ORDER-1)\n",
    "\t\t\tMARK_USED(index, current_order, area);\n",
    "\t\tzone->free_pages -= 1UL << order;\n",
    "\t\treturn expand(zone, page, index, order, current_order, area);\n",
    "\t}\n",
    "\n",
    "\treturn NULL;\n",
    "}\n",
    "\n",
    "static inline struct page *\n",
    "expand(struct zone *zone, struct page *page,\n",
    "\t unsigned long index, int low, int high, struct free_area *area)\n",
    "{\n",
    "\tunsigned long size = 1 << high;\n",
    "\n",
    "\twhile (high > low) {\n",
    "\t\tBUG_ON(bad_range(zone, page));\n",
    "\t\tarea--;\n",
    "\t\thigh--;\n",
    "\t\tsize >>= 1;\n",
    "\t\tlist_add(&page->list, &area->free_list);\n",
    "\t\tMARK_USED(index, high, area);\n",
    "\t\tindex += size;\n",
    "\t\tpage += size;\n",
    "\t}\n",
    "\treturn page;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "1. `__rmqueue` 从 `free_area` 里面取出大小合适的block\n",
    "\n",
    "2. `expand` 裁剪block。把block最后一段>=order 的内存返回，其他的放入到对应的list里面\n",
    "\n",
    "-----------------------\n",
    "\n",
    "### free one page\n",
    "\n",
    "```c\n",
    "/*\n",
    " * Freeing function for a buddy system allocator.\n",
    " *\n",
    " * The concept of a buddy system is to maintain direct-mapped table\n",
    " * (containing bit values) for memory blocks of various \"orders\".\n",
    " * The bottom level table contains the map for the smallest allocatable\n",
    " * units of memory (here, pages), and each level above it describes\n",
    " * pairs of units from the levels below, hence, \"buddies\".\n",
    " * At a high level, all that happens here is marking the table entry\n",
    " * at the bottom level available, and propagating the changes upward\n",
    " * as necessary, plus some accounting needed to play nicely with other\n",
    " * parts of the VM system.\n",
    " * At each level, we keep a list of pages, which are heads of continuous\n",
    " * free pages of length of (1 << order) and marked with PG_Private.Page's\n",
    " * order is recorded in page->private field.\n",
    " * So when we are allocating or freeing one, we can derive the state of the\n",
    " * other.  That is, if we allocate a small block, and both were   \n",
    " * free, the remainder of the region must be split into blocks.   \n",
    " * If a block is freed, and its buddy is also free, then this\n",
    " * triggers coalescing into a block of larger size.            \n",
    " *\n",
    " * -- wli\n",
    " */\n",
    "\n",
    "static inline void __free_pages_bulk (struct page *page, struct page *base,\n",
    "\t\tstruct zone *zone, unsigned int order)\n",
    "{\n",
    "\tunsigned long page_idx;\n",
    "\tstruct page *coalesced;\n",
    "\tint order_size = 1 << order;\n",
    "\n",
    "\tif (unlikely(order))\n",
    "\t\tdestroy_compound_page(page, order);\n",
    "\n",
    "\tpage_idx = page - base;\n",
    "\n",
    "\tBUG_ON(page_idx & (order_size - 1));\n",
    "\tBUG_ON(bad_range(zone, page));\n",
    "\n",
    "\tzone->free_pages += order_size;\n",
    "\twhile (order < MAX_ORDER-1) {\n",
    "\t\tstruct free_area *area;\n",
    "\t\tstruct page *buddy;\n",
    "\t\tint buddy_idx;\n",
    "\n",
    "\t\tbuddy_idx = (page_idx ^ (1 << order));\n",
    "\t\tbuddy = base + buddy_idx;\n",
    "\t\tif (bad_range(zone, buddy))\n",
    "\t\t\tbreak;\n",
    "\t\tif (!page_is_buddy(buddy, order))\n",
    "\t\t\tbreak;\n",
    "\t\t/* Move the buddy up one level. */\n",
    "\t\tlist_del(&buddy->lru);\n",
    "\t\tarea = zone->free_area + order;\n",
    "\t\tarea->nr_free--;\n",
    "\t\trmv_page_order(buddy);\n",
    "\t\tpage_idx &= buddy_idx;\n",
    "\t\torder++;\n",
    "\t}\n",
    "\tcoalesced = base + page_idx;\n",
    "\tset_page_order(coalesced, order);\n",
    "\tlist_add(&coalesced->lru, &zone->free_area[order].free_list);\n",
    "\tzone->free_area[order].nr_free++;\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "1. 每一个order block的起始地址一定是（1<<order)的整数倍，也就是(1<<(order-1))位置一定是0\n",
    "\n",
    "2. 因此，如果这个block和它同order的相邻block可以合并成（order+1）的block，那么如果这个block在（1<<order）处为0，那么就跟它后面一个同order的block合并，否则就跟它前面一个同order的block合并。因此这里寻找其buddy就直接用XOR(1<<order)。也就是减去（或者加上）（1<<order）。。。NICE！！！\n",
    "\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-CPU Page Frame Cache\n",
    "\n",
    "![percpu01](resources/percpu01.png)\n",
    "![percpu02](resources/percpu02.png)\n",
    "\n",
    "```c\n",
    "struct per_cpu_pages {\n",
    "\tint count;\t\t/* number of pages in the list */\n",
    "\tint low;\t\t/* low watermark, refill needed */\n",
    "\tint high;\t\t/* high watermark, emptying needed */\n",
    "\tint batch;\t\t/* chunk size for buddy add/remove */\n",
    "\tstruct list_head list;\t/* the list of pages */\n",
    "};\n",
    "\n",
    "struct per_cpu_pageset {\n",
    "\tstruct per_cpu_pages pcp[2];\t/* 0: hot.  1: cold */\n",
    "#ifdef CONFIG_NUMA\n",
    "\tunsigned long numa_hit;\t\t/* allocated in intended node */\n",
    "\tunsigned long numa_miss;\t/* allocated in non intended node */\n",
    "\tunsigned long numa_foreign;\t/* was intended here, hit elsewhere */\n",
    "\tunsigned long interleave_hit; \t/* interleaver prefered this zone */\n",
    "\tunsigned long local_node;\t/* allocation from local node */\n",
    "\tunsigned long other_node;\t/* allocation from other node */\n",
    "#endif\n",
    "} ____cacheline_aligned_in_smp;\n",
    "``` \n",
    "\n",
    "1. ZONE info can be get from /proc/zoneinfo\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linux2.6/mm/page_alloc.c\n",
    "\n",
    "### Allocating page frames though the per-CPU page frame caches\n",
    "\n",
    "\n",
    "```c\n",
    "/* \n",
    " * Obtain a specified number of elements from the buddy allocator, all under\n",
    " * a single hold of the lock, for efficiency.  Add them to the supplied list.\n",
    " * Returns the number of new pages which were placed at *list.\n",
    " */\n",
    "static int rmqueue_bulk(struct zone *zone, unsigned int order, \n",
    "\t\t\tunsigned long count, struct list_head *list)\n",
    "{\n",
    "\tunsigned long flags;\n",
    "\tint i;\n",
    "\tint allocated = 0;\n",
    "\tstruct page *page;\n",
    "\t\n",
    "\tspin_lock_irqsave(&zone->lock, flags);\n",
    "\tfor (i = 0; i < count; ++i) {\n",
    "\t\tpage = __rmqueue(zone, order);\n",
    "\t\tif (page == NULL)\n",
    "\t\t\tbreak;\n",
    "\t\tallocated++;\n",
    "\t\tlist_add_tail(&page->lru, list);\n",
    "\t}\n",
    "\tspin_unlock_irqrestore(&zone->lock, flags);\n",
    "\treturn allocated;\n",
    "}\n",
    "\n",
    "\n",
    "/*\n",
    " * Really, prep_compound_page() should be called from __rmqueue_bulk().  But\n",
    " * we cheat by calling it from here, in the order > 0 path.  Saves a branch\n",
    " * or two.\n",
    " */\n",
    "static struct page *\n",
    "buffered_rmqueue(struct zone *zone, int order, int gfp_flags)\n",
    "{\n",
    "\tunsigned long flags;\n",
    "\tstruct page *page = NULL;\n",
    "\tint cold = !!(gfp_flags & __GFP_COLD);\n",
    "\n",
    "\tif (order == 0) {\n",
    "\t\tstruct per_cpu_pages *pcp;\n",
    "\n",
    "\t\tpcp = &zone->pageset[get_cpu()].pcp[cold];\n",
    "\t\tlocal_irq_save(flags);\n",
    "\t\tif (pcp->count <= pcp->low)\n",
    "\t\t\tpcp->count += rmqueue_bulk(zone, 0,\n",
    "\t\t\t\t\t\tpcp->batch, &pcp->list);\n",
    "\t\tif (pcp->count) {\n",
    "\t\t\tpage = list_entry(pcp->list.next, struct page, lru);\n",
    "\t\t\tlist_del(&page->lru);\n",
    "\t\t\tpcp->count--;\n",
    "\t\t}\n",
    "\t\tlocal_irq_restore(flags);\n",
    "\t\tput_cpu();\n",
    "\t}\n",
    "\n",
    "\tif (page == NULL) {\n",
    "\t\tspin_lock_irqsave(&zone->lock, flags);\n",
    "\t\tpage = __rmqueue(zone, order);\n",
    "\t\tspin_unlock_irqrestore(&zone->lock, flags);\n",
    "\t}\n",
    "\n",
    "\tif (page != NULL) {\n",
    "\t\tBUG_ON(bad_range(zone, page));\n",
    "\t\tmod_page_state_zone(zone, pgalloc, 1 << order);\n",
    "\t\tprep_new_page(page, order);\n",
    "\n",
    "\t\tif (gfp_flags & __GFP_ZERO)\n",
    "\t\t\tprep_zero_page(page, order, gfp_flags);\n",
    "\n",
    "\t\tif (order && (gfp_flags & __GFP_COMP))\n",
    "\t\t\tprep_compound_page(page, order);\n",
    "\t}\n",
    "\treturn page;\n",
    "}\n",
    "```\n",
    "\n",
    "1. `int cold = !!(gfp_flags & __GFP_COLD);` small trick to get one bit value with out >>\n",
    "\n",
    "2. ![percpu03](resources/percpu03.png)\n",
    "\n",
    "3. ![percpu04](resources/percpu04.png)\n",
    "\n",
    "------------------\n",
    "\n",
    "### Release page frames to the per-CPU page frame caches\n",
    "\n",
    "```c\n",
    "/*\n",
    " * Free a 0-order page\n",
    " */\n",
    "static void FASTCALL(free_hot_cold_page(struct page *page, int cold));\n",
    "static void fastcall free_hot_cold_page(struct page *page, int cold)\n",
    "{\n",
    "\tstruct zone *zone = page_zone(page);\n",
    "\tstruct per_cpu_pages *pcp;\n",
    "\tunsigned long flags;\n",
    "\n",
    "\tarch_free_page(page, 0);\n",
    "\n",
    "\tkernel_map_pages(page, 1, 0);\n",
    "\tinc_page_state(pgfree);\n",
    "\tif (PageAnon(page))\n",
    "\t\tpage->mapping = NULL;\n",
    "\tfree_pages_check(__FUNCTION__, page);\n",
    "\tpcp = &zone->pageset[get_cpu()].pcp[cold];\n",
    "\tlocal_irq_save(flags);\n",
    "\tif (pcp->count >= pcp->high)\n",
    "\t\tpcp->count -= free_pages_bulk(zone, pcp->batch, &pcp->list, 0);\n",
    "\tlist_add(&page->lru, &pcp->list);\n",
    "\tpcp->count++;\n",
    "\tlocal_irq_restore(flags);\n",
    "\tput_cpu();\n",
    "}\n",
    "```\n",
    "\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Slab Allocator\n",
    "\n",
    "![slab01](resources/slab01.png)\n",
    "![slab02](resources/slab02.png)\n",
    "\n",
    "----------------------\n",
    "\n",
    "### cache mapping\n",
    "\n",
    "![cachemapping01](resources/cachemapping01.png)\n",
    "\n",
    "![cachemapping02](resources/cachemapping02.png)\n",
    "\n",
    "![cachemapping03](resources/cachemapping03.png)\n",
    "\n",
    "![cachemapping04](resources/cachemapping04.png)\n",
    "\n",
    "![cachemapping05](resources/cachemapping05.png)\n",
    "\n",
    "-----------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## slab coloring\n",
    "\n",
    "![slabcolor](resources/slabcolor01.png)\n",
    "![slabcolor](resources/slabcolor02.png)\n",
    "\n",
    "----------------------\n",
    "\n",
    "1. 我们拿到的每个slab，都会是在page对齐的位置，但是并不一定是连续的。\n",
    "\n",
    "2. 对于一个512K，8路，16Byte 长度cacheline的cache来讲，一共是512K / （8*16）= 4096 sets。如果我们分配的slab长度比较小，比如就是4K，一共有 4K / 16B = 256 个cacheline。因此也就只会用到前 256/4096 个sets。导致后面大量的cache用不到，所以引入slab coloring是有用处的\n",
    "\n",
    "3. 当slab很大的时候，这时候再加offset就没什么用了\n",
    "\n",
    "[reference](https://stackoverflow.com/questions/46731933/linux-slab-allocator-and-cache-performance/57345687#57345687)\n",
    "\n",
    "![slabcolor](resources/slabcolor03.png)\n",
    "![slabcolor](resources/slabcolor04.png)\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noncontigious Memory Area Management\n",
    "\n",
    "1. 无论是buddy system 还是 slab 分配，管理的都是physical memory pages。保证的是物理内存的连续性\n",
    "\n",
    "2. 对于大部分的应用，并不需要物理内存的连续性，只要线性内存连续就好了\n",
    "\n",
    "![nonc01](resources/noncontigious01.png)\n",
    "![nonc02](resources/noncontigious02.png)\n",
    "\n",
    "\n",
    "-------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paging directory\n",
    "\n",
    "![paging01](resources/paging01.png)\n",
    "![paging02](resources/paging02.png)\n",
    "![paging03](resources/paging03.png)\n",
    "\n",
    "------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d47d1382e92bbaf84c50276baa079056532326c20bdaac4b09430c41eda0c22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
